{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595702848430",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rabbit Image Downloader\n",
    "\n",
    "#### To train my neural network I had 5000 pictures each of dogs and cats but none of rabbits. The most obvious answer to finding 5000 images of rabbits was to scrape them off of Google Images. After looking through a few solutions, I found that this one from Anand Suresh which uses Selenium worked the best. \n",
    "\n",
    "## Problem\n",
    "#### The challenge I faced using this was an arbitrary download limit of around 125ish images per query. Some research led me down a rabbit hole of changes that Google pushed out to their search platforms (including image) relatively recently (mid 2020) while integrating BERT their new NLP model (link below). \n",
    "\n",
    "## Solution\n",
    "#### I wanted to get my feet wet with the neural network so instead of trying to figure out a way to query 5000 images (or any number higher than 150) I figured I could get similar results by just querying 50 different species of rabbit. This had the added benefit of making sure that the images i scraped were of a diversity of types so that my neural network would be more robust. Eventually I ran out of species and started querying the word \"rabbit\" in multiple languages, the theory being that websites where rabbits were tagged in their native languages might have different images of rabbits anyways.\n",
    "\n",
    "#### Of course in the process of scraping this many images I would come up with some images that were low quality or duplicates. I used the free Mac app, \"dupeguru\" to get rid of duplicate images and manually checked the images to make sure that they were of rabbits and  could be easily identified as rabbits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7117ac552099451391892fcdfc0789d5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "dalmation rabbit\nFound: 100 search results. Extracting links from 0:100\nFound: 101 image links, done!\nthrianta\nFound: 100 search results. Extracting links from 0:100\nFound: 100 image links, done!\nERROR - Could not save https://arba.net/wp-content/uploads/2018/12/Thrianta-300x259.jpg - cannot identify image file <_io.BytesIO object at 0x7f86b00188b0>\nERROR - Could not save https://quizlet.com/cdn-cgi/image/f=auto,fit=cover,h=200,onerror=redirect,w=240/https://o.quizlet.com/cz0u.0Ua.AH8Tx7LE5OlLQ.jpg - cannot identify image file <_io.BytesIO object at 0x7f86aff978b0>\nvelveteen lop rabbit\nFound: 100 search results. Extracting links from 0:100\nFound: 100 image links, done!\nERROR - Could not save https://www.elmwoodparkzoo.org/wp-content/uploads/2018/10/1920x1080-lop-rabbit.jpg - cannot identify image file <_io.BytesIO object at 0x7f86b00188b0>\n\n"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "search_terms = [\"rabbit\", \"bunny\", \"hare\", \"coney\", \"cute rabbit\", \"adopt rabbit\", \"english lop\", \"jersey wooly\", \"checkered giant rabbit\", \"mini rex\", \"blan de hotot\", \"belgian hare\", \"flemish giant rabbit\", \"mini lop\", \"californian rabbit\", \"american rabbit\", \"english spot\", \"dutch rabbit\", \"silver fox rabbit\", \"french lop\", \"netherland dwarf rabbit\", \"lionhead rabbit\", \"florida white rabbit\", \"holland lop\", \"new zealand white rabbit\", \"beveren rabbit\", \"polish rabbit\", \"rex rabbit\", \"tan rabbit\", \"himalayan rabbit\", \"cashmere lop\", \"british giant rabbit\", \"german rabbit\", \"meissner lop\", \"alaska rabbit\", \"american chinchilla rabbit\", \"american fuzzy lop\", \"argente de champagne\", \"beige rabbit\", \"big silver marten rabbit\", \"czech red rabbit\", \"Fauve de Bourgogne rabbit\", \"flemish giant rabbit\", \"giant chinchilla rabbit\", \"gotland rabbit\", \"harlequin rabbit\", \"havana rabbit\", \"japanese white rabbit\", \"jersey wooly rabbit\", \"rhinelander rabbit\", \"siberian rabbit\", \"swedish hare\", \"english lop\", \"jersey wooly\", \"checkered giant rabbit\", \"mini rex\", \"blan de hotot\", \"belgian hare\", \"flemish giant rabbit\", \"mini lop\", \"californian rabbit\", \"american rabbit\", \"english spot\", \"dutch rabbit\", \"silver fox rabbit\", \"french lop\", \"netherland dwarf rabbit\", \"lionhead rabbit\", \"florida white rabbit\", \"holland lop\", \"new zealand white rabbit\", \"beveren rabbit\", \"polish rabbit\", \"rex rabbit\", \"tan rabbit\", \"himalayan rabbit\", \"cashmere lop\", \"british giant rabbit\", \"german rabbit\", \"meissner lop\", \"alaska rabbit\", \"முயல்\", \"华南兔\", \"hainan hare\", \"Leporidae\", \"cottontail rabbit\"]\n",
    "    \n",
    "for i in tqdm_notebook(search_terms):\n",
    "    driver_path = \"/Users/shashankkalanithi/Documents/Data Science/Python Practice:Coding Examples/Instagram Comment Scraper/Instagram-Comments-Scraper-master/chromedriver\"\n",
    "    search_term = i\n",
    "    print(i)\n",
    "    search_and_download(\n",
    "        search_term=search_term, \n",
    "        driver_path=driver_path,\n",
    "        number_images=100, # You can only extract 100 images a query\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "import io\n",
    "from PIL import Image\n",
    "import hashlib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "###***Original Code from Anand Suresh***###\n",
    "\n",
    "#https://gist.github.com/Anandsure/6f62d54ddf40108fdc1a6aeae8c28c75#file-img_links-py\n",
    "\n",
    "\n",
    "def fetch_image_urls(query:str, max_links_to_fetch:int, wd:webdriver, sleep_between_interactions:int=1):\n",
    "    def scroll_to_end(wd):\n",
    "        wd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(sleep_between_interactions)    \n",
    "    \n",
    "    # build the google query\n",
    "    search_url = \"https://www.google.com/search?safe=off&site=&tbm=isch&source=hp&q={q}&oq={q}&gs_l=img\"\n",
    "\n",
    "    # load the page\n",
    "    wd.get(search_url.format(q=query))\n",
    "\n",
    "    image_urls = set()\n",
    "    image_count = 0\n",
    "    results_start = 0\n",
    "    while image_count < max_links_to_fetch:\n",
    "        scroll_to_end(wd)\n",
    "\n",
    "        # get all image thumbnail results\n",
    "        thumbnail_results = wd.find_elements_by_css_selector(\"img.Q4LuWd\")\n",
    "        number_results = len(thumbnail_results)\n",
    "        \n",
    "        print(f\"Found: {number_results} search results. Extracting links from {results_start}:{number_results}\")\n",
    "        \n",
    "        for img in thumbnail_results[results_start:number_results]:\n",
    "            # try to click every thumbnail such that we can get the real image behind it\n",
    "            try:\n",
    "                img.click()\n",
    "                time.sleep(sleep_between_interactions)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            # extract image urls    \n",
    "            actual_images = wd.find_elements_by_css_selector('img.n3VNCb')\n",
    "            for actual_image in actual_images:\n",
    "                if actual_image.get_attribute('src') and 'http' in actual_image.get_attribute('src'):\n",
    "                    image_urls.add(actual_image.get_attribute('src'))\n",
    "\n",
    "            image_count = len(image_urls)\n",
    "\n",
    "            if len(image_urls) >= max_links_to_fetch:\n",
    "                print(f\"Found: {len(image_urls)} image links, done!\")\n",
    "                break\n",
    "        else:\n",
    "            print(\"Found:\", len(image_urls), \"image links, looking for more ...\")\n",
    "            time.sleep(30)\n",
    "            return\n",
    "            load_more_button = wd.find_element_by_css_selector(\".mye4qd\")\n",
    "            if load_more_button:\n",
    "                wd.execute_script(\"document.querySelector('.mye4qd').click();\")\n",
    "\n",
    "        # move the result startpoint further down\n",
    "        results_start = len(thumbnail_results)\n",
    "\n",
    "    return image_urls\n",
    "\n",
    "\n",
    "def persist_image(folder_path:str,url:str):\n",
    "    try:\n",
    "        image_content = requests.get(url).content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR - Could not download {url} - {e}\")\n",
    "\n",
    "    try:\n",
    "        image_file = io.BytesIO(image_content)\n",
    "        image = Image.open(image_file).convert('RGB')\n",
    "        file_path = os.path.join(folder_path,hashlib.sha1(image_content).hexdigest()[:10] + '.jpg')\n",
    "        with open(file_path, 'wb') as f:\n",
    "            image.save(f, \"JPEG\", quality=85)\n",
    "        #print(f\"SUCCESS - saved {url} - as {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR - Could not save {url} - {e}\")\n",
    "\n",
    "\n",
    "def search_and_download(search_term:str,driver_path:str,target_path='./images',number_images=5):\n",
    "    target_folder = os.path.join(target_path,'_'.join(search_term.lower().split(' ')))\n",
    "\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.makedirs(target_folder)\n",
    "\n",
    "    with webdriver.Chrome(executable_path=driver_path) as wd:\n",
    "        res = fetch_image_urls(search_term, number_images, wd=wd, sleep_between_interactions=0.5)\n",
    "        \n",
    "    for elem in res:\n",
    "        persist_image(target_folder,elem)"
   ]
  }
 ]
}